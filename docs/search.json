[
  {
    "objectID": "blog.html",
    "href": "blog.html",
    "title": "Blog",
    "section": "",
    "text": "Order By\n       Default\n         \n          Title\n        \n         \n          Date - Oldest\n        \n         \n          Date - Newest\n        \n     \n  \n    \n      \n      \n    \n\n\n\n\n\n\n\n\n\n\n\n10 min\n\n\n\nquarto\n\n\nrmarkdown\n\n\nknitr\n\n\nkableExtra\n\n\nflextable\n\n\n\n\n\n\n\n\nOct 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 min\n\n\n\nnotes\n\n\nR\n\n\nRStudio\n\n\nMicrosoft\n\n\nOneDrive\n\n\nSharePoint\n\n\n\n\n\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n3 min\n\n\n\ntidyverse\n\n\ndplyr\n\n\nnotes\n\n\ncode\n\n\nR\n\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n6 min\n\n\n\nDocker\n\n\nRocker Project\n\n\nR\n\n\nRStudio\n\n\nLinux\n\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n4 min\n\n\n\nMicrosoft\n\n\nPowerBI\n\n\nM Code\n\n\nExcel\n\n\ncode\n\n\nnotes\n\n\n\n\n\n\n\nSep 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 min\n\n\n\nflatpak\n\n\nlinux\n\n\nnotes\n\n\ndebian\n\n\narchlinux\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n1 min\n\n\n\nR\n\n\nRstudio\n\n\ntidyverse\n\n\n\n\n\n\n\nSep 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n0 min\n\n\n\nnews\n\n\n\n\n\n\n\nSep 3, 2022\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "archive.html",
    "href": "archive.html",
    "title": "Archive",
    "section": "",
    "text": "Oct 10, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 20, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 13, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 7, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 5, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 4, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2022\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nSep 3, 2022\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2022-09-03-my-favorite-packages/index.html",
    "href": "posts/2022-09-03-my-favorite-packages/index.html",
    "title": "My favorite R packages",
    "section": "",
    "text": "Mind Blown\nJust the %>% operator alone radically changed my workflow and caused me to refactor all of my code (Hell, even R is integrating a pipe function now: |> in R 4.1+). Then learning how to use all of the data manipulation tools in dplyr (mutate, select, separate, oh how I could go on) made working with data exciting and intelligible instead of some chore full of arcane commands and confusing code.\nRMarkdown and now Quarto have given me many new avenues for reporting data, results, and analysis, even though I am still heavily tied to having to email an Excel file for some of the old-school folks (I guess if it ain’t broke…). Well, that’s why I learned some VBA too."
  },
  {
    "objectID": "posts/2022-09-03-welcome/index.html",
    "href": "posts/2022-09-03-welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "The github repository for the entire site can be found here."
  },
  {
    "objectID": "posts/2022-09-04-flatpak/index.html",
    "href": "posts/2022-09-04-flatpak/index.html",
    "title": "Some Notes About Flatpak",
    "section": "",
    "text": "After a few years of running ArchLinux on my NAS PC, I recently (a couple weeks ago?) decided to switch to a solid foundation of Debian Stable (Bullseye 11.4 at the time of this post), with most of my userland apps installed via Flatpak.\n\n\n\nFlatpak\n\n\nOne is not better than the other, but I was tired of having to regularly check for updates, decide if they looked important, check the homepage for any breakage news, etc. It’s not so bad for a desktop that is used for tinkering and playing, but for a fileserver running programs that I’d rather not restart all the time (hold on, let me pause this show on Plex and make sure my backup NAS isn’t syncing)…\nSo far so good. The overall system is smaller (due to Debian breaking up packages while Arch installs the kitchen sink at times), and it makes my root backup tarball smaller since I can leave out the flatpak directory and focus on the actual system."
  },
  {
    "objectID": "posts/2022-09-04-flatpak/index.html#flatpak-notes",
    "href": "posts/2022-09-04-flatpak/index.html#flatpak-notes",
    "title": "Some Notes About Flatpak",
    "section": "Flatpak Notes",
    "text": "Flatpak Notes\nAnyway, the main notes that I meant to put here are:\n\nflatpak remote-add flathub flathub-url is not the same as sudo flatpak remote-add flathub flathub-url\n*For a single-user system there’s not that much real difference in terms of the experience, but installing flathub without sudo only installs the repo for YOU and then any apps you install get saved in /home. You do you.\nFlatpak apps are installed at /var/lib/flatpak, so keep that as a separate BTRFS subvolume to exclude them from root backups.\nFor apps, MakeMKV in particular, the app’s personal root is /app/, not /.\nUser config files and data are mostly stored per-app in ~/.var/, but some apps have access to /home/user.\nAdd /var/lib/flatpak/exports/bin to you $PATH to more easily call the apps from the command line, in case error codes need to be looked at.\n\nOverall I’m pretty happy with the change. Most of the gui programs that I use are in flathub, so that’s pretty easy. I was worried about bloat and performance, but it’s really not that bad. Apps are sandboxed, yes, but they can share Flatpak libraries and runtimes so there isn’t so much redundancy. It’s really nice when installing a single Gnome app or Wine not to have to install an entire suite of Gnome apps and multi-lib stuff just for one program."
  },
  {
    "objectID": "posts/2022-09-05-powerbi-loop-files/index.html",
    "href": "posts/2022-09-05-powerbi-loop-files/index.html",
    "title": "Power Query Tip - Opening Multiple Files",
    "section": "",
    "text": "In this sort of environemnt, the suite of Power tools: PowerBI, Power Query, Power Pivot, etc. is a good choice. As a bonus, they play nicely with OneDrive and SharePoint, and PowerBI allows for automated data updating.\nIn my day-to-day I run into situations where I need to combine several Excel files that are split into chunks, say some sort of accounting information that is saved in separate files per year. Power Query’s GUI can help to get you started, but if you need to do any more complicated data wrangling you’ll need to dive into M code.\nA common template I use for the above scenario is something like this:\nlet\n  // Navigate to the SharePoint library (not folder) with the files.\n  Source = SharePoint.Files(\n    \"https://contoso.sharepoint.com/personal/tyler_contoso_com\",\n    [ApiVersion = 15]\n  ),\n  \n  // Filter the file list down to the correct folder\n  #\"Filtered Folders\" = Table.SelectRows(\n    Source, \n    each [Folder Path] = \"https://contoso.sharepoint.com/personal/tyler_contoso_com/Documents/Documents/Widget Exports/\"),\n    \n  // Filter down to just the right files.\n  // In this example, the files are named \"2022 Widget_Exports.xlsx\", \n  // \"2021 Widget_exports.xlsx\", etc.\n  #\"Filtered Files\" = Table.SelectRows(\n    #\"Filtered Folders\", \n    each Text.Contains([Name], \"Widget_Exports.xlsx\")\n    ),\n    \n  // Excel Opener Function\n  ExcelOpener = (folderPath, fileName) => \n  let\n    // This function nested in the main function processes all of\n    // the Excel files in the same way. It does not change the\n    // column types yet, that is saved for the end. I have had the \n    // column type information get tossed out in a following step,\n    // that's why it doesn't get defined here.\n    // The function does name the columns. \n    SelectFile = #\"Filtered Files\"{\n      [Name = fileName, \n      #\"Folder Path\" = folderPath]}[Content],\n      \n      #\"Imported Excel\" = Excel.Workbook(SelectFile, null, true),\n      \n      #\"Navigation\" = #\"Imported Excel\"{\n      [Item = \"Sheet\", Kind = \"Sheet\"]\n      }[Data],\n      \n      #\"Filtered rows\" = Table.SelectRows(\n        // If there are any merged cells, this can toss unnecessary rows\n        #\"Navigation\", each [Column2] <> null),\n        \n      #\"Promoted headers\" = Table.PromoteHeaders(\n      #\"Filtered rows\", [PromoteAllScalars = true]\n      )\n  in\n    #\"Promoted headers\",\n  \n  // To use the function, make a new column and get its values from the\n  // function. It will be a nested data column.\n  #\"Added Custom\" = Table.AddColumn(\n    #\"Filtered Files\", \n    \"Custom\", \n    each ExcelOpener([Folder Path], [Name])\n    ),\n  \n  // We can remove everything but the new column  \n  #\"Removed columns\" = Table.RemoveColumns(\n    #\"Added Custom\", \n    {\"Content\", \"Name\", \"Extension\", \"Date accessed\", \n      \"Date modified\", \"Date created\", \"Attributes\", \n      \"Folder Path\"}\n    ),\n  \n  // Expand the column and select all of the named columns  \n  #\"Expanded Custom\" = Table.ExpandTableColumn(\n    #\"Removed columns\", \n    \"Custom\", \n    {\"Acct No\", \"Cust No\", \"PO\", \"Transaction Date\", \"Widget Type\", \n      \"Widget Cost Per Unit\", \"Total Units\", \"Total Cost\", \n     \"Shipped\", \"Shipped Date\"}\n    ),\n  \n  // Now we will set the column types\n  #\"Changed column type\" = Table.TransformColumnTypes(\n    #\"Expanded Custom\", \n    {\n      {\"Acct No\", type text}, \n      {\"Cust No\", type text}, \n      {\"PO\", type text}, \n      {\"Transaction Date\", type date}, \n      {\"Widget Type\", type text}, \n      {\"Widget Cost Per Unit\", type number}, \n      {\"Total Units\", Int64.Type}, \n      {\"Total Cost\", type number}, \n      {\"Shipped\", logical}, \n      {\"Shipped Date\", type date}\n      }\n    )\nin\n  #\"Changed column type\"\nUsing code similar to this will combine the directory full of files into one big Power dataset that you can now modify as needed for the analysis or report that you are using."
  },
  {
    "objectID": "posts/2022-09-07-my-rstudio-setup/index.html",
    "href": "posts/2022-09-07-my-rstudio-setup/index.html",
    "title": "My Home RStudio Setup",
    "section": "",
    "text": "When I am working on, well, work-related work, I use my company-issued laptop with Windows, Microsoft Office tools, and an installation of RStudio Desktop.\nRecently I have been wanting to setup a personal installation of RStudio on my home file server as well. The main reasons being that RStudio makes for a great general-purpose IDE, and I’ve been wanting to start working with Quarto on some things, so right now seemed like a great time to figure it out."
  },
  {
    "objectID": "posts/2022-09-07-my-rstudio-setup/index.html#backstory",
    "href": "posts/2022-09-07-my-rstudio-setup/index.html#backstory",
    "title": "My Home RStudio Setup",
    "section": "Backstory",
    "text": "Backstory\nI wrote in a previous post that I am working on making my home file server more stable, which means moving more of the userland packages to containers. Most of the programs I use on that PC (Firefox, VLC, Gimp, etc.) all have flatpaks that work quite well for me.\nHowever, R and RStudio are not in that category. On Debian, both require going outside of the official Debian repositories: R has a repository for up-to-date versions, while RStudio does not (although they do provide binary downloads). Add to that the system dependencies of some packages and now there are random libraries installed all over, with no dependency chain in apt. There is the option to use the Debian packages from the CRAN repository, but those are not complete and have given me issues in the past, as far as permissions, updates, etc.\nIt seemed to me that R would need it’s own environment. How best to do that? I turned to Docker for this particular case.\n\n\n\nDocker"
  },
  {
    "objectID": "posts/2022-09-07-my-rstudio-setup/index.html#docker-setup",
    "href": "posts/2022-09-07-my-rstudio-setup/index.html#docker-setup",
    "title": "My Home RStudio Setup",
    "section": "Docker Setup",
    "text": "Docker Setup\n\nBase Image\nLuckily, smarter people than myself have already thought about this and started the Rocker Project. They have many different containers all built in layers on each other so it’s easy to find a good starting point for running R/shiny apps, or building a general dev environment like I was looking for.\n\n\nAdding on Layers\nAt the time of this post I chose the rocker/tidyverse image to build my RStudio environment, but this could change in the future (see my repo for the latest).1 Having Rstudio server and the tidyverse packages gets me 90% of the way to where I want to be, but there are other packages that I use quite a bit. To get those packages I would either need to\n\nOption 1:\n\nSpin up an image,\nDownload the packages in the image\nSave that modified environment as a new image via docker commit\n\nOption 2:\n\nCreate a Dockerfile and let docker build handle it\n\n\nI am a big fan of keeping things simple, reproducible, and mostly in line with the intended workflow (sometimes rules are made to be broken, but I am not familiar enough with docker to be getting my hands that dirty just yet), so I went with Option 2.\n\n\nConfiguration\nAt the time of this post, this is my Dockerfile:\nFROM rocker/tidyverse:4.2.1\nCOPY packages.R /home/rstudio/packages.R\nRUN R -q -e \"source('/home/rstudio/packages.R')\" \\\n    && rm -rf /tmp/* \\\n    && strip /usr/local/lib/R/site-library/*/libs/*.so\nI start with the rocker/tidyverse:4.2.1 image, then copy an R script into the rstudio home directory:\ninstall.packages(\n         c(\n           \"markdown\",\n           \"gt\", \n           \"DT\", \n           \"kableExtra\", \n           \"flextable\", \n           \"huxtable\", \n           \"reactable\", \n           \"formattable\", \n           \"pixiedust\", \n           \"agricolae\", \n           \"car\"\n         )\n)\nAfter the script is run, I execute 2 more commands to clean up the image (as advised by the Rocker team). This image is available on Docker Hub as tclark89/tidyverse-extra\nOne day I may dig more deeply into setting up my own very custom image by building something more from scratch, but for now the rocker/tidyverse image works as great jumping-off point.\n\n\nCompose\nNow that the image has been created it needs to be spun up, and it needs to be run with certain parameters. The best way to do that is with a docker-compose.yml file. Currently mine looks like this:\nservices:\n  rstudio:\n    image: tclark89/tidyverse-extra:4.2.1\n    ports: \n      - \"8787:8787\"\n    environment:\n      PASSWORD: rstudio\n      ROOT: true\n    volumes:\n      - ~/.config/rstudio:/home/rstudio/.config/rstudio\n      - ~/.local/share/rstudio:/home/rstudio/.local/share/rstudio\n      - ~/code/R:/home/rstudio/workspace\nThe docker-compose.yml file starts the rstudio service:\n\nUses my custom docker image as the base\nMaps the container ports\nSets the rstudio user’s password and gives it sudo via  environment variables\nMaps some directories to be shared between host and container. This lets settings and files persist in my /home directory between sessions.\n\nThe rocker team provides an example  compose file as well.\n\n\nRunning the Container\nAll it takes to run the docker container now is to cd to the directory with the docker-compose.yml file and issue the command: docker compose up. However, I would like for this to happen automatically so I can just login and go. There may be a different way to do this, but I went with a systemd service file.\nAfter some digging through the Arch Wiki and various SO posts I settled on the following:\n[Unit]\nDescription=%i service with docker compose\nPartOf=docker.service\nAfter=docker.service\n\n[Service]\nType=oneshot\nRemainAfterExit=true\nWorkingDirectory=/home/%u/docker/compose/%i\nExecStart=/usr/bin/docker compose up -d --remove-orphans\nExecStop=/usr/bin/docker-compose down\n\n[Install]\nWantedBy=multi-user.target\nThis service file is a user @.service, so the file is named docker-compose@.service and called via:\n\nsystemctl start --user docker-compose@tidyverse-extra.service\n\nor for a persistent setup:\n\nsystemctl enable --now --user docker-compose@tidyverse-extra.service\n\nBecause docker compose looks for a docker-compose.yml file in the working directory, I needed to specify one in this file and make sure that directory existed in my /home. The %u makes this file user-agnostic and the %i and @ make it usable for any other docker service I may decide to use later. I just need to make sure that I create a directory in ~/docker/compose/ and put the docker-compose.yml file there.\nAs a final note, this will only work if your user is part of the docker group, otherwise docker needs root privileges. This file could just as easily be made to work as root, but the docker-compose.yml file would need to have absolute paths instead of user-relative ones."
  },
  {
    "objectID": "posts/2022-09-07-my-rstudio-setup/index.html#using-rstudio",
    "href": "posts/2022-09-07-my-rstudio-setup/index.html#using-rstudio",
    "title": "My Home RStudio Setup",
    "section": "Using RStudio",
    "text": "Using RStudio\nNow that all of the pieces are in place, all I have to do to access RStudio at home is to open a broswer, access my file server at port 8787, and log in to RStudio Server. Then I can just git pull and get back to work on this website or whatever project I am focused on.\nFor now this all works wonderfully. I don’t have to muck around with dependencies on my server, and saving the docker files to GitHub and the image to Docker Hub means that it should be reproducible in case I can’t access the server. For instance, if I am away from home but want to work on a project I can spin up the docker image directly on my Chromebook (via the built-in Linux VM) and fire away. In fact, you can even run this image in a browser via Play with Docker, though it eats up quite a bit of RAM to do so."
  },
  {
    "objectID": "posts/2022-09-13-case_when/index.html",
    "href": "posts/2022-09-13-case_when/index.html",
    "title": "Dplyr’s case_when",
    "section": "",
    "text": "SQL\nSELECT \n  CASE \n    WHEN x = 1 THEN 'a'\n    WHEN x = 2 THEN 'b'\n    WHEN x = 3 THEN 'c'\n    ELSE 'd'\n  END  \ndplyr\ncase_when(\n  x == 1 ~ \"a\",\n  x == 2 ~ \"b\",\n  x == 3 ~ \"c\",\n  TRUE ~ \"d\"\n)\nLike in SQL, dplyr::case_when() works its way down the list of conditionals in the order that they appear. It’s good practice to include the TRUE ~ result statement at the end. Sometimes you may want an “other” result, other times you may just want to make sure that you’ve caught all the rows.\nFor a more detailed example:\n\n# Let's load some libraries:\nlibrary(tibble)\nlibrary(dplyr)\n\n\n# I'll use mtcars, and we'll look at the car model\nmtcarsMod <- mtcars |> \n  rownames_to_column(var=\"model\")\nhead(mtcarsMod)\n\n              model  mpg cyl disp  hp drat    wt  qsec vs am gear carb\n1         Mazda RX4 21.0   6  160 110 3.90 2.620 16.46  0  1    4    4\n2     Mazda RX4 Wag 21.0   6  160 110 3.90 2.875 17.02  0  1    4    4\n3        Datsun 710 22.8   4  108  93 3.85 2.320 18.61  1  1    4    1\n4    Hornet 4 Drive 21.4   6  258 110 3.08 3.215 19.44  1  0    3    1\n5 Hornet Sportabout 18.7   8  360 175 3.15 3.440 17.02  0  0    3    2\n6           Valiant 18.1   6  225 105 2.76 3.460 20.22  1  0    3    1\n\n\nLet’s say that we want to add the manufacturer as a separate column. There are a few ways to do it:\n\nNested if_else\nThe first way that always enters my head is to do nested if_else statements. It’s not terrible when there are only a few options, but they get ugly fast:\n\nmtcarsMod |> \n  mutate(make = if_else(grepl(\"Mazda\", model), \"Mazda\", \n                        if_else(grepl(\"Hornet\", model), \"Hornet\",\n                                if_else(grepl(\"Merc\", model), \"Mercury\",\n                                        if_else(grepl(\"Datsun\", model), \"Datsun\", \n                                                # etc.\n                                                \"Other\"))))) |> \n  select(make, names(mtcarsMod)) |>\n  rmarkdown::paged_table()\n\n\n\n  \n\n\n\n\n\nMultiple mutates\nOne way to make things cleaner is to do multiple mutates. Create the new column with your “catch-all” value, then use conditional statements that leave the new column unchanged when the condition is FALSE:\n\nmtcarsMod |> \n  mutate(\n    make = \"Other\",\n    make = if_else(grepl(\"Mazda\", model), \"Mazda\", make),\n    make = if_else(grepl(\"Hornet\", model), \"Hornet\", make),\n    make = if_else(grepl(\"Merc\", model), \"Mercury\", make),\n    make = if_else(grepl(\"Datsun\", model), \"Datsun\", make)\n    # etc.\n  ) |> \n  select(make, names(mtcarsMod)) |>\n  rmarkdown::paged_table()\n\n\n\n  \n\n\n\n\n\ncase_when\nBut the cleanest way (IMHO) is to use case_when. I don’t know why I always forget about it, but maybe the act of making this post will permanently etch it into my brain.\n\nmtcarsMod |> \n  mutate(make = case_when(\n    grepl(\"Mazda\", model) ~ \"Mazda\",\n    grepl(\"Hornet\", model) ~ \"Hornet\",\n    grepl(\"Merc\", model) ~ \"Mercury\",\n    grepl(\"Datsun\", model) ~ \"Datsun\",\n    # etc.\n    TRUE ~ \"Other\"\n  )) |> \n   select(make, names(mtcarsMod)) |>\n  rmarkdown::paged_table()"
  },
  {
    "objectID": "posts/2022-09-20-onedrive-and-r/index.html",
    "href": "posts/2022-09-20-onedrive-and-r/index.html",
    "title": "Using R and RStudio with OneDrive/SharePoint",
    "section": "",
    "text": "Love it or hate it, but Microsoft is fairly ubiquitous in any business environment. That could be reliance on Excel spreadsheets and Word documents up to full-blown Azure environments, PowerBI reports, etc.\nI have learned that there are some times when R and OneDrive butt heads, so here are some tips for making them get along:"
  },
  {
    "objectID": "posts/2022-09-20-onedrive-and-r/index.html#tip-1-dont-install-r-to-a-onedrive-folder",
    "href": "posts/2022-09-20-onedrive-and-r/index.html#tip-1-dont-install-r-to-a-onedrive-folder",
    "title": "Using R and RStudio with OneDrive/SharePoint",
    "section": "Tip 1: Don’t install R to a OneDrive folder",
    "text": "Tip 1: Don’t install R to a OneDrive folder\nNewer versions of R don’t suggest this anymore, but be sure not to install R into a OneDrive synced folder like Documents. It sounds like a good idea for portability, but updates will throw a great big wrench into things in a hurry, trust me. This also applies to related software like quarto, rtools, python/conda, really anything that can be installed locally as a normal user."
  },
  {
    "objectID": "posts/2022-09-20-onedrive-and-r/index.html#tip-2-no-r-projects-with-some-caveats",
    "href": "posts/2022-09-20-onedrive-and-r/index.html#tip-2-no-r-projects-with-some-caveats",
    "title": "Using R and RStudio with OneDrive/SharePoint",
    "section": "Tip 2: No R Projects (with some caveats)",
    "text": "Tip 2: No R Projects (with some caveats)\nUnfortunately, this will also throw a wrench into things. R Studio makes a lot tiny folders with very deep folder trees and you can very quickly run into Window’s character limits. This is a major issue for RMarkdown/Quarto documents, and will break the ability to view code output without rendering. And then when you do render, all of those tiny deeply-nested files get changed and OneDrive loses it’s mind trying to track the changes. In fact, even when not using R Projects, it’s a good idea to wait a little while between document renders for this very reason.\nThe only real way to use R Projects is to keep them outside of OneDrive folders. That works well, but then you lose the backup features of OneDrive. It really depends on your company’s storage environment.\nIn lieu of R Projects, the best suggestion I have is to make a new folder for any project you’re working on and keep all scripts and outputs there. It’s not the same as a project but it will get the job done."
  },
  {
    "objectID": "posts/2022-09-20-onedrive-and-r/index.html#tip-3-always-keep-on-this-device",
    "href": "posts/2022-09-20-onedrive-and-r/index.html#tip-3-always-keep-on-this-device",
    "title": "Using R and RStudio with OneDrive/SharePoint",
    "section": "Tip 3: Always keep on this device",
    "text": "Tip 3: Always keep on this device\nThis option (via right-click in Windows Explorer) is a life-saver for reading data from shared locations. There’s just not a good way that I know of to access documents in the OneDrive/SharePoint cloud, so keeping them synced on your local PC is the only way. reaxl::read_xlsx attempting access a file seems to trigger Windows to download said file, but not always. And if a file is unchanged or unopened (at least as far as Windows knows) for a certain amount of time, that file may get removed locally to save storage space and then your scripts to read data will stop working."
  },
  {
    "objectID": "posts/2022-10-10-quarto-tables-workflow/index.html",
    "href": "posts/2022-10-10-quarto-tables-workflow/index.html",
    "title": "My Approach to Tables in Quarto Documents",
    "section": "",
    "text": "Whenever possible I try to use graphs and plots to back up my story about data analysis. That said, sometimes you’ve just got use some data tables. That could be summary statistics, regression/ANOVA tables, or maybe wedding the visual aids by creating sparklines or mini-plots within a table.\nIn 2022 there are no shortage of R libraries for making beautiful graphs and tables, but my most commonly used tools right now are kableExtra and flextable. gt looks promising but it’s still fairly new. I’ve tried using huxtable but for whatever reason it’s never quite clicked with me. DT is a great library but I try to avoid it for rmarkdown/quarto documents due to how large it blows up HTML files. It’s great when I need to include a full dataset in a report though, or in Shiny apps."
  },
  {
    "objectID": "posts/2022-10-10-quarto-tables-workflow/index.html#html-tables",
    "href": "posts/2022-10-10-quarto-tables-workflow/index.html#html-tables",
    "title": "My Approach to Tables in Quarto Documents",
    "section": "HTML Tables",
    "text": "HTML Tables\nI am unaware of any pdf-exclusive r table libraries, but that doesn’t mean they don’t exist. All of the previously mentioned tables can produce HTML tables, but I really only use:\n\nkableExtra\nflextable\nDT\n\nmostly in that order.\n\n\nCode\nlibrary(dplyr)\n\n\n\nkableExtra\nkableExtra is my go-to for HTML tables in my documents. I think the default settings look pretty good, and it’s easy to tweak them to get exactly what I want.\n\n\nCode\niris |> \n  group_by(Species) |> \n  summarise(across(.fns=list(mean=mean, sd=sd))) |> \n  kableExtra::kbl(\n    col.names = c(\"Species\", rep(c(\"Mean\", \"SD\"), 4)),\n    digits=1\n  ) |> \n  kableExtra::add_header_above(\n    c(\" \", \n      \"Sepal Length\"=2, \n      \"Sepal Width\"=2,\n      \"Petal Length\"=2,\n      \"Petal Width\"=2), \n    align = \"c\"\n  ) |> \n  kableExtra::kable_styling(\n    bootstrap_options = c(\"hover\", \"responsive\")\n  )\n\n\n\nIris Data - kableExtra\n \n\n\nSepal Length\nSepal Width\nPetal Length\nPetal Width\n\n  \n    Species \n    Mean \n    SD \n    Mean \n    SD \n    Mean \n    SD \n    Mean \n    SD \n  \n \n\n  \n    setosa \n    5.0 \n    0.4 \n    3.4 \n    0.4 \n    1.5 \n    0.2 \n    0.2 \n    0.1 \n  \n  \n    versicolor \n    5.9 \n    0.5 \n    2.8 \n    0.3 \n    4.3 \n    0.5 \n    1.3 \n    0.2 \n  \n  \n    virginica \n    6.6 \n    0.6 \n    3.0 \n    0.3 \n    5.6 \n    0.6 \n    2.0 \n    0.3 \n  \n\n\n\n\n\nIt’s pretty easy to get a nice-looking table, and I really like the “hover” and “responsive” bootstrap options in kableExtra::kable_styling(). Hover gives a quasi-interactive feel to the table, without having to load all the javascript required for sorting, filtering, etc. DT is better suited for that level of interactivity, but most tables probably don’t need that.\n\n\nflextable\nFlextable also makes pretty nice HTML tables, but they are more static than kableExtra’s.\n\n\nCode\niris |> \n  group_by(Species) |> \n  summarise(across(.fns=list(mean=mean, sd=sd))) |> \n  flextable::flextable() |> \n  flextable::set_header_labels(\n    Sepal.Length_mean = \"Mean\",\n    Sepal.Length_sd = \"SD\",\n    Sepal.Width_mean = \"Mean\",\n    Sepal.Width_sd = \"SD\",\n    Petal.Length_mean = \"Mean\",\n    Petal.Length_sd = \"SD\",\n    Petal.Width_mean = \"Mean\",\n    Petal.Width_sd = \"SD\"\n  ) |> \n  flextable::add_header_row(\n    values=c(\"\", \"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\"),\n    colwidths = c(1, 2, 2, 2, 2)\n  ) |> \n  flextable::colformat_double(j=2:9, digits=1) |> \n  flextable::align(i=1, j=2:9, align=\"center\", part=\"header\")\n\n\n\nIris data - flextableSepal LengthSepal WidthPetal LengthPetal WidthSpeciesMeanSDMeanSDMeanSDMeanSDsetosa5.00.43.40.41.50.20.20.1versicolor5.90.52.80.34.30.51.30.2virginica6.60.63.00.35.60.62.00.3\n\n\n\n\nSome differences\nOne of the big differences between the 2 packages is how you make changes. kableExtra, being based on knitr, leans towards to original R paradigm of a few functions with a lot of internal options, while flextable leans more towards to modern approach of several small functions that have a few options each. Neither approach is better than the other. With many small functions there are more commands that have to be remembered, but they are usually named in a way that easily explains what they do, and they are typically logicial to read and don’t require memorizing (and maintaining!) as much documentation. One drawback is having to nest all of those functions, or store output to variables over and over, but pipe functions (|> or %>%) have largely eliminate that problem. Now the only thing to watch for is long strings of spaghetti code, but that’s an issue regardless.\n\n\nDT\nDT is where I turn to in Shiny, or when I need to include a dataset as a table, but I try to avoid that.\n\n\nCode\niris |> \n  DT::datatable(\n    caption = \"Iris data- DT\",\n    filter=\"top\") |> \n  DT::formatRound(1:4, digits = 1)\n\n\n\n\n\n\n\nIt’s a pretty neat library, but I get overwhelmed with all of the options. Especially since many of the options are set by passing HTML/CSS and javascript code directly into the R code. Luckily there are some helpful guides from Rstudio and from the authors"
  },
  {
    "objectID": "posts/2022-10-10-quarto-tables-workflow/index.html#pdf-tables",
    "href": "posts/2022-10-10-quarto-tables-workflow/index.html#pdf-tables",
    "title": "My Approach to Tables in Quarto Documents",
    "section": "PDF Tables",
    "text": "PDF Tables\nkableExtra and flextable can also make really nice PDF tables as well. For small tables I lean towards flextable just because I think it looks “better” right away. For longer tables I lean towards kableExtra because of some of the row highlighting and spacing it does easily. Let’s see some examples\n\nkableExtra\n\n\nCode\niris |> \n  group_by(Species) |> \n  summarise(across(.fns=list(mean=mean, sd=sd))) |> \n  kableExtra::kbl(\n    booktabs = T,\n    col.names = c(\"Species\", rep(c(\"Mean\", \"SD\"), 4)),\n    digits=1\n  ) |> \n  kableExtra::add_header_above(\n    c(\" \", \n      \"Sepal Length\"=2, \n      \"Sepal Width\"=2,\n      \"Petal Length\"=2,\n      \"Petal Width\"=2), \n    align = \"c\"\n  ) |> \n  kableExtra::kable_classic_2() \n\n\n\n\n\nkableExtra PDF Table\n\n\nI ran the above code in a PDF format quarto document with mainfont: Cambria. I really don’t care for the default LaTeX font. Using the various styling functions in kableExtra speeds up the layout process. I tend not to use them for HTML tables though, just kable_styling().\nFor longer tables in a PDF document I make use of the latex_options flag in kable_styling():\n\n\nCode\niris |> \n  head(20) |> \n  kableExtra::kbl(\n    booktabs = T,\n    col.names = c(\"Sepal Length\", \"Sepal Width\", \n                  \"Petal Length\", \"Petal Width\",\n                  \"Species\"),\n    digits=1\n  ) |> \n  kableExtra::kable_classic_2() |> \n  kableExtra::kable_styling(latex_options = \"striped\")\n\n\n\n\n\nkableExtra Long PDF Table\n\n\nThe default of adding a little extra vertical padding every 5 lines, along with the striped option helps readability.\n\n\nFlextable\nFor this flextable example, I used the exact same code as the previous HTML example, but ran it in a PDF format quarto document. The library really lives up to it’s name!\n\n\n\nflextable PDF Table\n\n\nLonger flextables are where I run into issues though:\n\n\nCode\nevens <- function(x) subset(x, x %% 2 == 0)\nfives <- function(x) subset(x, x %% 5 == 0)\n\nirisSubset <- iris |> \n  head(20) \n\nirisSubset |> \n  flextable::flextable() |> \n  flextable::set_header_labels(\n    Sepal.Length=\"Sepal Length\", \n    Sepal.Width=\"Sepal Width\", \n    Petal.Length=\"Petal Length\", \n    Petal.Width=\"Petal Width\") |> \n  flextable::align(j=5, align=\"center\", part=\"all\") |> \n  flextable::bg(i=evens(c(1:length(irisSubset[,1]))), bg=\"#eeeeee\") |> \n  flextable::padding(i=fives(c(1:length(irisSubset[,1]))), padding.bottom = 20) |> \n  flextable::autofit()\n\n\n\n\n\nflextable Long PDF Table\n\n\nThe color and padding have to be manually defined which adds to code length and complexity. That’s not always a bad thing, but unfortunately not all of this code works in both HTML and PDF. flextable::padding() is the main issue. Theoretically you could add blank rows or something but that just further clutters up the code when you could just use kableExtra. In general, I find that simpler is better when it come to LaTeX and flextable."
  },
  {
    "objectID": "posts/2022-10-10-quarto-tables-workflow/index.html#microsoft-output",
    "href": "posts/2022-10-10-quarto-tables-workflow/index.html#microsoft-output",
    "title": "My Approach to Tables in Quarto Documents",
    "section": "Microsoft output",
    "text": "Microsoft output\nMost of the table libraries are focused on HTML, so outputting to Word usually involves using webshot to save a png and insert it into the document, or tossing out most of the formatting with a markdown table.\n\nkableExtra\nIf you use the prefer-html: true option in the YAML header, kableExtra can output simple markdown tables into a document:\n\n\n\nkableExtra Small Docx Table\n\n\n\n\n\nkableExtra Long Docx Table\n\n\nBut notice that they lose most of the formatting options that were applied. Also notice that while there is a caption, Word didn’t recognize it as the table caption so there is no numbering or document linking, and that’s even with using Quarto’s tbl-cap chunk option!\n\n\nflextable\nFlextable was designed to generate real MS Office tables though:\n\n\n\nflextable Small Docx Table\n\n\n\n\n\nflextable Long Docx Table\n\n\nThese tables look pretty good (if nothing else they’re drawn exactly as I told flextable). The padding option also works in Word documents. As before, the flextable output all uses the same code for HTML, PDF, and Docx report formats."
  },
  {
    "objectID": "posts/2022-10-10-quarto-tables-workflow/index.html#closing-thoughts",
    "href": "posts/2022-10-10-quarto-tables-workflow/index.html#closing-thoughts",
    "title": "My Approach to Tables in Quarto Documents",
    "section": "Closing thoughts",
    "text": "Closing thoughts\nIn general, when I am making tables in an HTML document I’ll go with kableExtra because it very quickly gets me on the right track. However, there are many, many other options. When I am working with PDF documents I’ll use flextable for the simple stuff and kableExtra when I need better control over the LaTeX code being generated. When I am making Word documents, there’s really no better choice than flextable.\n\nQuarto/RMarkdown Tip\nI often create HTML and PDF/Docx reports for the same data. HTML is great for opening on a screen and interacting with the report, while PDF/Word can be more easily emailed, printed, etc. To facilitate my above mentioned table choices, I use the following code early in the document:\n\n\nCode\nis_html <- knitr::is_html_output()\n\n\nWhen the report is being compiled, the variable is_html will be TRUE for HTML documents and FALSE for all others. Then I can define functions like:\n\nSmall TableLong Table\n\n\n\n\nCode\nirisSumm <- iris |> \n  group_by(Species) |> \n  summarise(across(.fns=list(mean=mean, sd=sd))) \n\nif(is_html){\n  \n  irisSumm |> \n    kableExtra::kbl(\n      col.names = c(\"Species\", rep(c(\"Mean\", \"SD\"), 4)),\n      digits=1\n    ) |> \n    kableExtra::add_header_above(\n      c(\" \", \n        \"Sepal Length\"=2, \n        \"Sepal Width\"=2,\n        \"Petal Length\"=2,\n        \"Petal Width\"=2), \n      align = \"c\"\n    ) |> \n    kableExtra::kable_styling(\n      bootstrap_options = c(\"hover\", \"responsive\")\n    )\n  \n} else {\n  \n  irisSumm |> \n    flextable::flextable() |> \n    flextable::set_header_labels(\n      Sepal.Length_mean = \"Mean\",\n      Sepal.Length_sd = \"SD\",\n      Sepal.Width_mean = \"Mean\",\n      Sepal.Width_sd = \"SD\",\n      Petal.Length_mean = \"Mean\",\n      Petal.Length_sd = \"SD\",\n      Petal.Width_mean = \"Mean\",\n      Petal.Width_sd = \"SD\"\n    ) |> \n    flextable::add_header_row(\n      values=c(\"\", \"Sepal Length\", \"Sepal Width\", \"Petal Length\", \"Petal Width\"),\n      colwidths = c(1, 2, 2, 2, 2)\n    ) |> \n    flextable::colformat_double(j=2:9, digits=1) |> \n    flextable::align(i=1, j=2:9, align=\"center\", part=\"header\")\n  \n}\n\n\n\n\n\n\nCode\nevens <- function(x) subset(x, x %% 2 == 0)\nfives <- function(x) subset(x, x %% 5 == 0)\n\nirisSubset <- iris |> \n  head(20)  \n\nif(is_html){\n  \n  irisSubset |> \n    kableExtra::kbl(\n      booktabs = T,\n      col.names = c(\"Sepal Length\", \"Sepal Width\", \n                    \"Petal Length\", \"Petal Width\",\n                    \"Species\"),\n      digits=1\n    ) |> \n    kableExtra::kable_styling(bootstrap_options = c(\"hover\", \"responsive\", \"condensed\"))\n  \n} else{\n\nirisSubset |> \n  flextable::flextable() |> \n  flextable::set_header_labels(\n    Sepal.Length=\"Sepal Length\", \n    Sepal.Width=\"Sepal Width\", \n    Petal.Length=\"Petal Length\", \n    Petal.Width=\"Petal Width\") |> \n  flextable::align(j=5, align=\"center\", part=\"all\") |> \n  flextable::bg(i=evens(c(1:length(irisSubset[,1]))), bg=\"#eeeeee\") |> \n  flextable::padding(i=fives(c(1:length(irisSubset[,1]))), padding.bottom = 20) |> \n  flextable::autofit()\n\n}"
  }
]